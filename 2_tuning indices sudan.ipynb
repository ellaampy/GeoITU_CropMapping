{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46e2b975-f2fc-4fb5-907b-e6e621bede9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import optuna\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefd903a-9782-4c3b-9235-98fc365068a4",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "834de924-a816-43a3-afe0-d7810d4f9844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 51, 15) (500,)\n"
     ]
    }
   ],
   "source": [
    "country = 'sudan'\n",
    "mode = 'Train'\n",
    "feature = 'indices'\n",
    "\n",
    "path = '/app/stella/dev/GeoITU/data'\n",
    "\n",
    "X_indices = np.load(os.path.join(path, '{}_{}_{}.npy'.format(country, mode, feature)), allow_pickle=True)\n",
    "y_labels = np.load(os.path.join(path, '{}_{}_labels.npy'.format(country, mode)), allow_pickle=True)\n",
    "\n",
    "            \n",
    "print(X_indices.shape, y_labels.shape)\n",
    "assert X_indices.shape[0] == y_labels.shape[0]\n",
    "\n",
    "X_indices = X_indices.reshape(X_indices.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332c0dfe-a722-4755-b0df-ff186fd7f135",
   "metadata": {},
   "source": [
    "## rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c040f6d8-dbe4-4b2b-ae87-9ef3990bc26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-10-03 17:07:18,590]\u001b[0m A new study created in memory with name: no-name-90a34b10-6fe1-499c-8aab-ed0e11326611\u001b[0m\n",
      "\u001b[32m[I 2023-10-03 17:07:20,856]\u001b[0m Trial 0 finished with value: 0.98 and parameters: {'n_estimators': 668, 'max_depth': 12, 'min_samples_split': 16, 'bootstrap': True, 'n_jobs': -1}. Best is trial 0 with value: 0.98.\u001b[0m\n",
      "\u001b[32m[I 2023-10-03 17:07:21,514]\u001b[0m Trial 1 finished with value: 0.99 and parameters: {'n_estimators': 167, 'max_depth': 14, 'min_samples_split': 31, 'bootstrap': True, 'n_jobs': -1}. Best is trial 1 with value: 0.99.\u001b[0m\n",
      "\u001b[32m[I 2023-10-03 17:07:23,227]\u001b[0m Trial 2 finished with value: 0.99 and parameters: {'n_estimators': 684, 'max_depth': 6, 'min_samples_split': 26, 'bootstrap': False, 'n_jobs': -1}. Best is trial 1 with value: 0.99.\u001b[0m\n",
      "\u001b[32m[I 2023-10-03 17:07:24,692]\u001b[0m Trial 3 finished with value: 0.99 and parameters: {'n_estimators': 573, 'max_depth': 11, 'min_samples_split': 30, 'bootstrap': False, 'n_jobs': -1}. Best is trial 1 with value: 0.99.\u001b[0m\n",
      "\u001b[32m[I 2023-10-03 17:07:25,192]\u001b[0m Trial 4 finished with value: 0.99 and parameters: {'n_estimators': 124, 'max_depth': 6, 'min_samples_split': 8, 'bootstrap': True, 'n_jobs': -1}. Best is trial 1 with value: 0.99.\u001b[0m\n",
      "\u001b[32m[I 2023-10-03 17:07:27,656]\u001b[0m Trial 5 finished with value: 0.99 and parameters: {'n_estimators': 783, 'max_depth': 5, 'min_samples_split': 31, 'bootstrap': True, 'n_jobs': -1}. Best is trial 1 with value: 0.99.\u001b[0m\n",
      "\u001b[32m[I 2023-10-03 17:07:30,096]\u001b[0m Trial 6 finished with value: 0.99 and parameters: {'n_estimators': 776, 'max_depth': 13, 'min_samples_split': 16, 'bootstrap': True, 'n_jobs': -1}. Best is trial 1 with value: 0.99.\u001b[0m\n",
      "\u001b[32m[I 2023-10-03 17:07:31,264]\u001b[0m Trial 7 finished with value: 0.98 and parameters: {'n_estimators': 434, 'max_depth': 11, 'min_samples_split': 5, 'bootstrap': False, 'n_jobs': -1}. Best is trial 1 with value: 0.99.\u001b[0m\n",
      "\u001b[32m[I 2023-10-03 17:07:31,904]\u001b[0m Trial 8 finished with value: 0.99 and parameters: {'n_estimators': 187, 'max_depth': 9, 'min_samples_split': 28, 'bootstrap': True, 'n_jobs': -1}. Best is trial 1 with value: 0.99.\u001b[0m\n",
      "\u001b[32m[I 2023-10-03 17:07:33,229]\u001b[0m Trial 9 finished with value: 0.99 and parameters: {'n_estimators': 408, 'max_depth': 13, 'min_samples_split': 16, 'bootstrap': True, 'n_jobs': -1}. Best is trial 1 with value: 0.99.\u001b[0m\n",
      "\u001b[32m[I 2023-10-03 17:07:35,669]\u001b[0m Trial 10 finished with value: 0.98 and parameters: {'n_estimators': 973, 'max_depth': 15, 'min_samples_split': 23, 'bootstrap': False, 'n_jobs': -1}. Best is trial 1 with value: 0.99.\u001b[0m\n",
      "\u001b[32m[I 2023-10-03 17:07:36,540]\u001b[0m Trial 11 finished with value: 0.99 and parameters: {'n_estimators': 358, 'max_depth': 3, 'min_samples_split': 26, 'bootstrap': False, 'n_jobs': -1}. Best is trial 1 with value: 0.99.\u001b[0m\n",
      "\u001b[32m[I 2023-10-03 17:07:37,426]\u001b[0m Trial 12 finished with value: 0.99 and parameters: {'n_estimators': 288, 'max_depth': 8, 'min_samples_split': 23, 'bootstrap': False, 'n_jobs': -1}. Best is trial 1 with value: 0.99.\u001b[0m\n",
      "\u001b[32m[I 2023-10-03 17:07:39,086]\u001b[0m Trial 13 finished with value: 0.99 and parameters: {'n_estimators': 578, 'max_depth': 7, 'min_samples_split': 32, 'bootstrap': False, 'n_jobs': -1}. Best is trial 1 with value: 0.99.\u001b[0m\n",
      "\u001b[32m[I 2023-10-03 17:07:41,505]\u001b[0m Trial 14 finished with value: 0.99 and parameters: {'n_estimators': 988, 'max_depth': 4, 'min_samples_split': 24, 'bootstrap': False, 'n_jobs': -1}. Best is trial 1 with value: 0.99.\u001b[0m\n",
      "\u001b[32m[I 2023-10-03 17:07:44,009]\u001b[0m Trial 15 finished with value: 0.99 and parameters: {'n_estimators': 766, 'max_depth': 15, 'min_samples_split': 20, 'bootstrap': True, 'n_jobs': -1}. Best is trial 1 with value: 0.99.\u001b[0m\n",
      "\u001b[32m[I 2023-10-03 17:07:45,644]\u001b[0m Trial 16 finished with value: 0.99 and parameters: {'n_estimators': 500, 'max_depth': 9, 'min_samples_split': 27, 'bootstrap': True, 'n_jobs': -1}. Best is trial 1 with value: 0.99.\u001b[0m\n",
      "\u001b[32m[I 2023-10-03 17:07:47,834]\u001b[0m Trial 17 finished with value: 0.99 and parameters: {'n_estimators': 917, 'max_depth': 3, 'min_samples_split': 20, 'bootstrap': False, 'n_jobs': -1}. Best is trial 1 with value: 0.99.\u001b[0m\n",
      "\u001b[32m[I 2023-10-03 17:07:48,670]\u001b[0m Trial 18 finished with value: 0.99 and parameters: {'n_estimators': 262, 'max_depth': 9, 'min_samples_split': 13, 'bootstrap': True, 'n_jobs': -1}. Best is trial 1 with value: 0.99.\u001b[0m\n",
      "\u001b[32m[I 2023-10-03 17:07:50,164]\u001b[0m Trial 19 finished with value: 0.98 and parameters: {'n_estimators': 451, 'max_depth': 10, 'min_samples_split': 14, 'bootstrap': True, 'n_jobs': -1}. Best is trial 1 with value: 0.99.\u001b[0m\n",
      "\u001b[32m[I 2023-10-03 17:07:51,271]\u001b[0m Trial 20 finished with value: 0.98 and parameters: {'n_estimators': 343, 'max_depth': 13, 'min_samples_split': 11, 'bootstrap': True, 'n_jobs': -1}. Best is trial 1 with value: 0.99.\u001b[0m\n",
      "\u001b[32m[I 2023-10-03 17:07:52,138]\u001b[0m Trial 21 finished with value: 0.99 and parameters: {'n_estimators': 223, 'max_depth': 7, 'min_samples_split': 28, 'bootstrap': False, 'n_jobs': -1}. Best is trial 1 with value: 0.99.\u001b[0m\n",
      "\u001b[32m[I 2023-10-03 17:07:54,189]\u001b[0m Trial 22 finished with value: 0.99 and parameters: {'n_estimators': 857, 'max_depth': 4, 'min_samples_split': 21, 'bootstrap': False, 'n_jobs': -1}. Best is trial 1 with value: 0.99.\u001b[0m\n",
      "\u001b[32m[I 2023-10-03 17:07:55,041]\u001b[0m Trial 23 finished with value: 0.99 and parameters: {'n_estimators': 350, 'max_depth': 3, 'min_samples_split': 12, 'bootstrap': False, 'n_jobs': -1}. Best is trial 1 with value: 0.99.\u001b[0m\n",
      "\u001b[32m[I 2023-10-03 17:07:55,837]\u001b[0m Trial 24 finished with value: 0.99 and parameters: {'n_estimators': 278, 'max_depth': 7, 'min_samples_split': 28, 'bootstrap': False, 'n_jobs': -1}. Best is trial 1 with value: 0.99.\u001b[0m\n",
      "\u001b[32m[I 2023-10-03 17:07:56,475]\u001b[0m Trial 25 finished with value: 0.98 and parameters: {'n_estimators': 249, 'max_depth': 8, 'min_samples_split': 23, 'bootstrap': False, 'n_jobs': -1}. Best is trial 1 with value: 0.99.\u001b[0m\n",
      "\u001b[32m[I 2023-10-03 17:07:57,759]\u001b[0m Trial 26 finished with value: 0.98 and parameters: {'n_estimators': 493, 'max_depth': 9, 'min_samples_split': 19, 'bootstrap': False, 'n_jobs': -1}. Best is trial 1 with value: 0.99.\u001b[0m\n",
      "\u001b[32m[I 2023-10-03 17:07:59,182]\u001b[0m Trial 27 finished with value: 0.99 and parameters: {'n_estimators': 571, 'max_depth': 5, 'min_samples_split': 26, 'bootstrap': False, 'n_jobs': -1}. Best is trial 1 with value: 0.99.\u001b[0m\n",
      "\u001b[32m[I 2023-10-03 17:08:00,143]\u001b[0m Trial 28 finished with value: 0.99 and parameters: {'n_estimators': 342, 'max_depth': 6, 'min_samples_split': 10, 'bootstrap': False, 'n_jobs': -1}. Best is trial 1 with value: 0.99.\u001b[0m\n",
      "\u001b[32m[I 2023-10-03 17:08:01,729]\u001b[0m Trial 29 finished with value: 0.99 and parameters: {'n_estimators': 656, 'max_depth': 4, 'min_samples_split': 24, 'bootstrap': False, 'n_jobs': -1}. Best is trial 1 with value: 0.99.\u001b[0m\n",
      "\u001b[32m[I 2023-10-03 17:08:04,130]\u001b[0m Trial 30 finished with value: 0.99 and parameters: {'n_estimators': 998, 'max_depth': 5, 'min_samples_split': 29, 'bootstrap': False, 'n_jobs': -1}. Best is trial 1 with value: 0.99.\u001b[0m\n",
      "\u001b[32m[I 2023-10-03 17:08:06,003]\u001b[0m Trial 31 finished with value: 0.99 and parameters: {'n_estimators': 701, 'max_depth': 6, 'min_samples_split': 17, 'bootstrap': False, 'n_jobs': -1}. Best is trial 1 with value: 0.99.\u001b[0m\n",
      "\u001b[32m[I 2023-10-03 17:08:07,595]\u001b[0m Trial 32 finished with value: 0.98 and parameters: {'n_estimators': 618, 'max_depth': 5, 'min_samples_split': 21, 'bootstrap': False, 'n_jobs': -1}. Best is trial 1 with value: 0.99.\u001b[0m\n",
      "\u001b[32m[I 2023-10-03 17:08:08,931]\u001b[0m Trial 33 finished with value: 0.99 and parameters: {'n_estimators': 524, 'max_depth': 3, 'min_samples_split': 27, 'bootstrap': False, 'n_jobs': -1}. Best is trial 1 with value: 0.99.\u001b[0m\n",
      "\u001b[32m[I 2023-10-03 17:08:11,200]\u001b[0m Trial 34 finished with value: 0.99 and parameters: {'n_estimators': 704, 'max_depth': 4, 'min_samples_split': 30, 'bootstrap': True, 'n_jobs': -1}. Best is trial 1 with value: 0.99.\u001b[0m\n",
      "\u001b[32m[I 2023-10-03 17:08:13,370]\u001b[0m Trial 35 finished with value: 0.99 and parameters: {'n_estimators': 886, 'max_depth': 4, 'min_samples_split': 18, 'bootstrap': False, 'n_jobs': -1}. Best is trial 1 with value: 0.99.\u001b[0m\n",
      "\u001b[32m[I 2023-10-03 17:08:15,481]\u001b[0m Trial 36 finished with value: 0.99 and parameters: {'n_estimators': 892, 'max_depth': 3, 'min_samples_split': 18, 'bootstrap': False, 'n_jobs': -1}. Best is trial 1 with value: 0.99.\u001b[0m\n",
      "\u001b[32m[I 2023-10-03 17:08:17,791]\u001b[0m Trial 37 finished with value: 0.99 and parameters: {'n_estimators': 739, 'max_depth': 6, 'min_samples_split': 14, 'bootstrap': True, 'n_jobs': -1}. Best is trial 1 with value: 0.99.\u001b[0m\n",
      "\u001b[32m[I 2023-10-03 17:08:19,934]\u001b[0m Trial 38 finished with value: 0.99 and parameters: {'n_estimators': 661, 'max_depth': 4, 'min_samples_split': 13, 'bootstrap': True, 'n_jobs': -1}. Best is trial 1 with value: 0.99.\u001b[0m\n",
      "\u001b[32m[I 2023-10-03 17:08:21,734]\u001b[0m Trial 39 finished with value: 0.99 and parameters: {'n_estimators': 634, 'max_depth': 5, 'min_samples_split': 9, 'bootstrap': False, 'n_jobs': -1}. Best is trial 1 with value: 0.99.\u001b[0m\n",
      "\u001b[32m[I 2023-10-03 17:08:23,210]\u001b[0m Trial 40 finished with value: 0.99 and parameters: {'n_estimators': 619, 'max_depth': 5, 'min_samples_split': 5, 'bootstrap': False, 'n_jobs': -1}. Best is trial 1 with value: 0.99.\u001b[0m\n",
      "\u001b[32m[I 2023-10-03 17:08:24,713]\u001b[0m Trial 41 finished with value: 0.98 and parameters: {'n_estimators': 577, 'max_depth': 5, 'min_samples_split': 5, 'bootstrap': False, 'n_jobs': -1}. Best is trial 1 with value: 0.99.\u001b[0m\n",
      "\u001b[32m[I 2023-10-03 17:08:26,706]\u001b[0m Trial 42 finished with value: 0.99 and parameters: {'n_estimators': 819, 'max_depth': 6, 'min_samples_split': 30, 'bootstrap': False, 'n_jobs': -1}. Best is trial 1 with value: 0.99.\u001b[0m\n",
      "\u001b[32m[I 2023-10-03 17:08:27,283]\u001b[0m Trial 43 finished with value: 0.99 and parameters: {'n_estimators': 176, 'max_depth': 7, 'min_samples_split': 8, 'bootstrap': False, 'n_jobs': -1}. Best is trial 1 with value: 0.99.\u001b[0m\n",
      "\u001b[32m[I 2023-10-03 17:08:27,627]\u001b[0m Trial 44 finished with value: 0.98 and parameters: {'n_estimators': 104, 'max_depth': 7, 'min_samples_split': 26, 'bootstrap': False, 'n_jobs': -1}. Best is trial 1 with value: 0.99.\u001b[0m\n",
      "\u001b[32m[I 2023-10-03 17:08:28,104]\u001b[0m Trial 45 finished with value: 0.98 and parameters: {'n_estimators': 174, 'max_depth': 8, 'min_samples_split': 8, 'bootstrap': False, 'n_jobs': -1}. Best is trial 1 with value: 0.99.\u001b[0m\n",
      "\u001b[32m[I 2023-10-03 17:08:28,781]\u001b[0m Trial 46 finished with value: 0.99 and parameters: {'n_estimators': 236, 'max_depth': 5, 'min_samples_split': 6, 'bootstrap': False, 'n_jobs': -1}. Best is trial 1 with value: 0.99.\u001b[0m\n",
      "\u001b[32m[I 2023-10-03 17:08:29,613]\u001b[0m Trial 47 finished with value: 0.99 and parameters: {'n_estimators': 335, 'max_depth': 6, 'min_samples_split': 10, 'bootstrap': False, 'n_jobs': -1}. Best is trial 1 with value: 0.99.\u001b[0m\n",
      "\u001b[32m[I 2023-10-03 17:08:30,679]\u001b[0m Trial 48 finished with value: 0.98 and parameters: {'n_estimators': 387, 'max_depth': 7, 'min_samples_split': 7, 'bootstrap': False, 'n_jobs': -1}. Best is trial 1 with value: 0.99.\u001b[0m\n",
      "\u001b[32m[I 2023-10-03 17:08:31,517]\u001b[0m Trial 49 finished with value: 0.99 and parameters: {'n_estimators': 304, 'max_depth': 8, 'min_samples_split': 32, 'bootstrap': False, 'n_jobs': -1}. Best is trial 1 with value: 0.99.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 167, 'max_depth': 14, 'min_samples_split': 31, 'bootstrap': True, 'n_jobs': -1}\n",
      "Fold 1 Accuracy: 0.99\n",
      "Fold 1 F_score: 0.98999899989999\n",
      "Fold 2 Accuracy: 0.99\n",
      "Fold 2 F_score: 0.98999899989999\n",
      "Fold 3 Accuracy: 0.98\n",
      "Fold 3 F_score: 0.98\n",
      "Fold 4 Accuracy: 0.99\n",
      "Fold 4 F_score: 0.98999899989999\n",
      "Fold 5 Accuracy: 0.97\n",
      "Fold 5 F_score: 0.9699729756781104\n",
      "Average Accuracy across all folds: 0.9840\n",
      "Average Fscore across all folds: 0.9800\n"
     ]
    }
   ],
   "source": [
    "# Setting up the stratified k-fold cross-validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "accuracies = []  # List to store accuracy of each fold\n",
    "f1_scores = []\n",
    "fold_num = 0\n",
    "num_trial = 50\n",
    "\n",
    "# 5-fold Stratified Cross Validation loop\n",
    "for train_index, test_index in skf.split(X_indices, y_labels):\n",
    "    fold_num += 1\n",
    "\n",
    "    # Splitting the dataset for this fold\n",
    "    X_train, X_test = [X_indices[i] for i in train_index], [X_indices[i] for i in test_index]\n",
    "    y_train_labels, y_test_labels = [y_labels[i] for i in train_index], [\n",
    "        y_labels[i] for i in test_index\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    # optimize params for single fold\n",
    "    if fold_num == 1:  \n",
    "\n",
    "\n",
    "        def objective(trial):\n",
    "            params = {\n",
    "            'n_estimators' : trial.suggest_int('n_estimators', 100, 1000),\n",
    "            'max_depth' : trial.suggest_int('max_depth', 3, 15),\n",
    "            # 'max_features' : trial.suggest_categorical('max_features', ['auto', 'sqrt']), \n",
    "            'min_samples_split' : trial.suggest_int('min_samples_split', 5, 32),\n",
    "            'bootstrap' : trial.suggest_categorical('bootstrap', [True, False]),\n",
    "            'n_jobs' : trial.suggest_categorical('n_jobs', [-1]) #fixed. use all cpus\n",
    "            }\n",
    "\n",
    "            clf = RandomForestClassifier(**params)\n",
    "            clf.fit(X_train, y_train_labels)\n",
    "\n",
    "            # Making predictions on the test set\n",
    "            y_pred = clf.predict(X_test)\n",
    "\n",
    "            # Calculating and reporting the accuracy\n",
    "            accuracy = accuracy_score(y_test_labels, y_pred)\n",
    "            return accuracy\n",
    "\n",
    "\n",
    "        # optimize study\n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=num_trial) \n",
    "        print(study.best_params)\n",
    "                        \n",
    "    # Model training\n",
    "    clf = RandomForestClassifier(**study.best_params)  # change classifier here\n",
    "    clf.fit(X_train, y_train_labels)\n",
    "    \n",
    "    # clf = xgb.XGBClassifier()\n",
    "    # clf.fit(X_train, le.transform(y_train_labels))\n",
    "\n",
    "    # Making predictions on the test set\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Calculating and reporting the accuracy\n",
    "    accuracy = accuracy_score(y_test_labels, y_pred)\n",
    "    accuracies.append(accuracy)  # Storing the accuracy\n",
    "    \n",
    "    # Calculating and reporting the fscore\n",
    "    f_score = f1_score(y_test_labels, y_pred, average='weighted')\n",
    "    f_scores.append(f_score)  # Storing the accuracy\n",
    "    print(f\"Fold {fold_num} Accuracy: {accuracy}\")\n",
    "    print(f\"Fold {fold_num} F_score: {f_score}\")\n",
    "\n",
    "# Reporting the final results\n",
    "avg_accuracy = np.mean(accuracies)\n",
    "avg_fscore = np.mean(f_scores)\n",
    "print(f\"Average Accuracy across all folds: {avg_accuracy:.4f}\")\n",
    "print(f\"Average Fscore across all folds: {avg_fscore:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
