{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46e2b975-f2fc-4fb5-907b-e6e621bede9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import optuna\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefd903a-9782-4c3b-9235-98fc365068a4",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "834de924-a816-43a3-afe0-d7810d4f9844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 18, 15) (500,)\n",
      "(500, 180)\n"
     ]
    }
   ],
   "source": [
    "country = 'afghan'\n",
    "mode = 'Train'\n",
    "feature = 'indices'\n",
    "\n",
    "path = '/app/stella/dev/GeoITU/data'\n",
    "\n",
    "X_indices = np.load(os.path.join(path, '{}_{}_{}.npy'.format(country, mode, feature)), allow_pickle=True)\n",
    "y_labels = np.load(os.path.join(path, '{}_{}_labels.npy'.format(country, mode)), allow_pickle=True)\n",
    "\n",
    "            \n",
    "print(X_indices.shape, y_labels.shape)\n",
    "assert X_indices.shape[0] == y_labels.shape[0]\n",
    "\n",
    "X_indices = X_indices[:,:12].reshape(X_indices.shape[0], -1)\n",
    "print(X_indices.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332c0dfe-a722-4755-b0df-ff186fd7f135",
   "metadata": {},
   "source": [
    "## rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c040f6d8-dbe4-4b2b-ae87-9ef3990bc26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-10-05 20:00:39,858]\u001b[0m A new study created in memory with name: no-name-1677838a-786b-467e-99d3-d1fc22556b93\u001b[0m\n",
      "\u001b[32m[I 2023-10-05 20:00:41,450]\u001b[0m Trial 0 finished with value: 0.76 and parameters: {'n_estimators': 491, 'max_depth': 4, 'min_samples_split': 18, 'bootstrap': True, 'n_jobs': -1}. Best is trial 0 with value: 0.76.\u001b[0m\n",
      "\u001b[32m[I 2023-10-05 20:00:41,795]\u001b[0m Trial 1 finished with value: 0.75 and parameters: {'n_estimators': 149, 'max_depth': 3, 'min_samples_split': 15, 'bootstrap': False, 'n_jobs': -1}. Best is trial 0 with value: 0.76.\u001b[0m\n",
      "\u001b[32m[I 2023-10-05 20:00:43,544]\u001b[0m Trial 2 finished with value: 0.76 and parameters: {'n_estimators': 748, 'max_depth': 4, 'min_samples_split': 5, 'bootstrap': False, 'n_jobs': -1}. Best is trial 0 with value: 0.76.\u001b[0m\n",
      "\u001b[32m[I 2023-10-05 20:00:45,471]\u001b[0m Trial 3 finished with value: 0.76 and parameters: {'n_estimators': 799, 'max_depth': 11, 'min_samples_split': 32, 'bootstrap': False, 'n_jobs': -1}. Best is trial 0 with value: 0.76.\u001b[0m\n",
      "\u001b[32m[I 2023-10-05 20:00:46,546]\u001b[0m Trial 4 finished with value: 0.77 and parameters: {'n_estimators': 325, 'max_depth': 11, 'min_samples_split': 11, 'bootstrap': True, 'n_jobs': -1}. Best is trial 4 with value: 0.77.\u001b[0m\n",
      "\u001b[32m[I 2023-10-05 20:00:47,374]\u001b[0m Trial 5 finished with value: 0.76 and parameters: {'n_estimators': 333, 'max_depth': 4, 'min_samples_split': 13, 'bootstrap': False, 'n_jobs': -1}. Best is trial 4 with value: 0.77.\u001b[0m\n",
      "\u001b[32m[I 2023-10-05 20:00:50,519]\u001b[0m Trial 6 finished with value: 0.77 and parameters: {'n_estimators': 968, 'max_depth': 10, 'min_samples_split': 19, 'bootstrap': True, 'n_jobs': -1}. Best is trial 4 with value: 0.77.\u001b[0m\n",
      "\u001b[32m[I 2023-10-05 20:00:52,574]\u001b[0m Trial 7 finished with value: 0.77 and parameters: {'n_estimators': 801, 'max_depth': 8, 'min_samples_split': 29, 'bootstrap': False, 'n_jobs': -1}. Best is trial 4 with value: 0.77.\u001b[0m\n",
      "\u001b[32m[I 2023-10-05 20:00:53,001]\u001b[0m Trial 8 finished with value: 0.77 and parameters: {'n_estimators': 155, 'max_depth': 8, 'min_samples_split': 17, 'bootstrap': False, 'n_jobs': -1}. Best is trial 4 with value: 0.77.\u001b[0m\n",
      "\u001b[32m[I 2023-10-05 20:00:55,446]\u001b[0m Trial 9 finished with value: 0.75 and parameters: {'n_estimators': 760, 'max_depth': 13, 'min_samples_split': 24, 'bootstrap': True, 'n_jobs': -1}. Best is trial 4 with value: 0.77.\u001b[0m\n",
      "\u001b[32m[I 2023-10-05 20:00:56,749]\u001b[0m Trial 10 finished with value: 0.75 and parameters: {'n_estimators': 392, 'max_depth': 15, 'min_samples_split': 6, 'bootstrap': True, 'n_jobs': -1}. Best is trial 4 with value: 0.77.\u001b[0m\n",
      "\u001b[32m[I 2023-10-05 20:00:59,962]\u001b[0m Trial 11 finished with value: 0.77 and parameters: {'n_estimators': 998, 'max_depth': 10, 'min_samples_split': 11, 'bootstrap': True, 'n_jobs': -1}. Best is trial 4 with value: 0.77.\u001b[0m\n",
      "\u001b[32m[I 2023-10-05 20:01:01,878]\u001b[0m Trial 12 finished with value: 0.75 and parameters: {'n_estimators': 598, 'max_depth': 12, 'min_samples_split': 23, 'bootstrap': True, 'n_jobs': -1}. Best is trial 4 with value: 0.77.\u001b[0m\n",
      "\u001b[32m[I 2023-10-05 20:01:05,072]\u001b[0m Trial 13 finished with value: 0.76 and parameters: {'n_estimators': 988, 'max_depth': 7, 'min_samples_split': 10, 'bootstrap': True, 'n_jobs': -1}. Best is trial 4 with value: 0.77.\u001b[0m\n",
      "\u001b[32m[I 2023-10-05 20:01:06,017]\u001b[0m Trial 14 finished with value: 0.78 and parameters: {'n_estimators': 290, 'max_depth': 14, 'min_samples_split': 22, 'bootstrap': True, 'n_jobs': -1}. Best is trial 14 with value: 0.78.\u001b[0m\n",
      "\u001b[32m[I 2023-10-05 20:01:06,967]\u001b[0m Trial 15 finished with value: 0.77 and parameters: {'n_estimators': 289, 'max_depth': 15, 'min_samples_split': 25, 'bootstrap': True, 'n_jobs': -1}. Best is trial 14 with value: 0.78.\u001b[0m\n",
      "\u001b[32m[I 2023-10-05 20:01:07,889]\u001b[0m Trial 16 finished with value: 0.78 and parameters: {'n_estimators': 244, 'max_depth': 13, 'min_samples_split': 21, 'bootstrap': True, 'n_jobs': -1}. Best is trial 14 with value: 0.78.\u001b[0m\n",
      "\u001b[32m[I 2023-10-05 20:01:08,680]\u001b[0m Trial 17 finished with value: 0.76 and parameters: {'n_estimators': 227, 'max_depth': 13, 'min_samples_split': 22, 'bootstrap': True, 'n_jobs': -1}. Best is trial 14 with value: 0.78.\u001b[0m\n",
      "\u001b[32m[I 2023-10-05 20:01:10,234]\u001b[0m Trial 18 finished with value: 0.75 and parameters: {'n_estimators': 492, 'max_depth': 14, 'min_samples_split': 28, 'bootstrap': True, 'n_jobs': -1}. Best is trial 14 with value: 0.78.\u001b[0m\n",
      "\u001b[32m[I 2023-10-05 20:01:11,707]\u001b[0m Trial 19 finished with value: 0.77 and parameters: {'n_estimators': 436, 'max_depth': 13, 'min_samples_split': 20, 'bootstrap': True, 'n_jobs': -1}. Best is trial 14 with value: 0.78.\u001b[0m\n",
      "\u001b[32m[I 2023-10-05 20:01:12,062]\u001b[0m Trial 20 finished with value: 0.75 and parameters: {'n_estimators': 103, 'max_depth': 15, 'min_samples_split': 27, 'bootstrap': True, 'n_jobs': -1}. Best is trial 14 with value: 0.78.\u001b[0m\n",
      "\u001b[32m[I 2023-10-05 20:01:12,895]\u001b[0m Trial 21 finished with value: 0.75 and parameters: {'n_estimators': 251, 'max_depth': 12, 'min_samples_split': 21, 'bootstrap': True, 'n_jobs': -1}. Best is trial 14 with value: 0.78.\u001b[0m\n",
      "\u001b[32m[I 2023-10-05 20:01:14,123]\u001b[0m Trial 22 finished with value: 0.75 and parameters: {'n_estimators': 386, 'max_depth': 13, 'min_samples_split': 21, 'bootstrap': True, 'n_jobs': -1}. Best is trial 14 with value: 0.78.\u001b[0m\n",
      "\u001b[32m[I 2023-10-05 20:01:16,034]\u001b[0m Trial 23 finished with value: 0.75 and parameters: {'n_estimators': 607, 'max_depth': 10, 'min_samples_split': 16, 'bootstrap': True, 'n_jobs': -1}. Best is trial 14 with value: 0.78.\u001b[0m\n",
      "\u001b[32m[I 2023-10-05 20:01:18,905]\u001b[0m Trial 24 finished with value: 0.76 and parameters: {'n_estimators': 876, 'max_depth': 6, 'min_samples_split': 8, 'bootstrap': True, 'n_jobs': -1}. Best is trial 14 with value: 0.78.\u001b[0m\n",
      "\u001b[32m[I 2023-10-05 20:01:20,214]\u001b[0m Trial 25 finished with value: 0.76 and parameters: {'n_estimators': 402, 'max_depth': 14, 'min_samples_split': 20, 'bootstrap': True, 'n_jobs': -1}. Best is trial 14 with value: 0.78.\u001b[0m\n",
      "\u001b[32m[I 2023-10-05 20:01:21,794]\u001b[0m Trial 26 finished with value: 0.75 and parameters: {'n_estimators': 456, 'max_depth': 14, 'min_samples_split': 26, 'bootstrap': True, 'n_jobs': -1}. Best is trial 14 with value: 0.78.\u001b[0m\n",
      "\u001b[32m[I 2023-10-05 20:01:22,538]\u001b[0m Trial 27 finished with value: 0.78 and parameters: {'n_estimators': 230, 'max_depth': 12, 'min_samples_split': 14, 'bootstrap': True, 'n_jobs': -1}. Best is trial 14 with value: 0.78.\u001b[0m\n",
      "\u001b[32m[I 2023-10-05 20:01:23,247]\u001b[0m Trial 28 finished with value: 0.77 and parameters: {'n_estimators': 207, 'max_depth': 12, 'min_samples_split': 16, 'bootstrap': True, 'n_jobs': -1}. Best is trial 14 with value: 0.78.\u001b[0m\n",
      "\u001b[32m[I 2023-10-05 20:01:25,006]\u001b[0m Trial 29 finished with value: 0.76 and parameters: {'n_estimators': 547, 'max_depth': 11, 'min_samples_split': 14, 'bootstrap': True, 'n_jobs': -1}. Best is trial 14 with value: 0.78.\u001b[0m\n",
      "\u001b[32m[I 2023-10-05 20:01:25,579]\u001b[0m Trial 30 finished with value: 0.76 and parameters: {'n_estimators': 176, 'max_depth': 14, 'min_samples_split': 18, 'bootstrap': True, 'n_jobs': -1}. Best is trial 14 with value: 0.78.\u001b[0m\n",
      "\u001b[32m[I 2023-10-05 20:01:26,437]\u001b[0m Trial 31 finished with value: 0.76 and parameters: {'n_estimators': 264, 'max_depth': 15, 'min_samples_split': 25, 'bootstrap': True, 'n_jobs': -1}. Best is trial 14 with value: 0.78.\u001b[0m\n",
      "\u001b[32m[I 2023-10-05 20:01:27,422]\u001b[0m Trial 32 finished with value: 0.76 and parameters: {'n_estimators': 299, 'max_depth': 15, 'min_samples_split': 23, 'bootstrap': True, 'n_jobs': -1}. Best is trial 14 with value: 0.78.\u001b[0m\n",
      "\u001b[32m[I 2023-10-05 20:01:28,057]\u001b[0m Trial 33 finished with value: 0.76 and parameters: {'n_estimators': 182, 'max_depth': 12, 'min_samples_split': 15, 'bootstrap': True, 'n_jobs': -1}. Best is trial 14 with value: 0.78.\u001b[0m\n",
      "\u001b[32m[I 2023-10-05 20:01:28,365]\u001b[0m Trial 34 finished with value: 0.77 and parameters: {'n_estimators': 106, 'max_depth': 13, 'min_samples_split': 19, 'bootstrap': False, 'n_jobs': -1}. Best is trial 14 with value: 0.78.\u001b[0m\n",
      "\u001b[32m[I 2023-10-05 20:01:28,729]\u001b[0m Trial 35 finished with value: 0.76 and parameters: {'n_estimators': 137, 'max_depth': 11, 'min_samples_split': 18, 'bootstrap': False, 'n_jobs': -1}. Best is trial 14 with value: 0.78.\u001b[0m\n",
      "\u001b[32m[I 2023-10-05 20:01:29,848]\u001b[0m Trial 36 finished with value: 0.77 and parameters: {'n_estimators': 346, 'max_depth': 13, 'min_samples_split': 13, 'bootstrap': True, 'n_jobs': -1}. Best is trial 14 with value: 0.78.\u001b[0m\n",
      "\u001b[32m[I 2023-10-05 20:01:30,953]\u001b[0m Trial 37 finished with value: 0.77 and parameters: {'n_estimators': 346, 'max_depth': 9, 'min_samples_split': 13, 'bootstrap': True, 'n_jobs': -1}. Best is trial 14 with value: 0.78.\u001b[0m\n",
      "\u001b[32m[I 2023-10-05 20:01:31,912]\u001b[0m Trial 38 finished with value: 0.76 and parameters: {'n_estimators': 347, 'max_depth': 9, 'min_samples_split': 12, 'bootstrap': False, 'n_jobs': -1}. Best is trial 14 with value: 0.78.\u001b[0m\n",
      "\u001b[32m[I 2023-10-05 20:01:33,348]\u001b[0m Trial 39 finished with value: 0.75 and parameters: {'n_estimators': 486, 'max_depth': 3, 'min_samples_split': 30, 'bootstrap': True, 'n_jobs': -1}. Best is trial 14 with value: 0.78.\u001b[0m\n",
      "\u001b[32m[I 2023-10-05 20:01:34,472]\u001b[0m Trial 40 finished with value: 0.78 and parameters: {'n_estimators': 433, 'max_depth': 14, 'min_samples_split': 20, 'bootstrap': False, 'n_jobs': -1}. Best is trial 14 with value: 0.78.\u001b[0m\n",
      "\u001b[32m[I 2023-10-05 20:01:35,012]\u001b[0m Trial 41 finished with value: 0.77 and parameters: {'n_estimators': 205, 'max_depth': 12, 'min_samples_split': 16, 'bootstrap': False, 'n_jobs': -1}. Best is trial 14 with value: 0.78.\u001b[0m\n",
      "\u001b[32m[I 2023-10-05 20:01:35,599]\u001b[0m Trial 42 finished with value: 0.76 and parameters: {'n_estimators': 218, 'max_depth': 14, 'min_samples_split': 16, 'bootstrap': False, 'n_jobs': -1}. Best is trial 14 with value: 0.78.\u001b[0m\n",
      "\u001b[32m[I 2023-10-05 20:01:36,277]\u001b[0m Trial 43 finished with value: 0.76 and parameters: {'n_estimators': 273, 'max_depth': 8, 'min_samples_split': 17, 'bootstrap': False, 'n_jobs': -1}. Best is trial 14 with value: 0.78.\u001b[0m\n",
      "\u001b[32m[I 2023-10-05 20:01:36,606]\u001b[0m Trial 44 finished with value: 0.78 and parameters: {'n_estimators': 117, 'max_depth': 14, 'min_samples_split': 19, 'bootstrap': False, 'n_jobs': -1}. Best is trial 14 with value: 0.78.\u001b[0m\n",
      "\u001b[32m[I 2023-10-05 20:01:37,346]\u001b[0m Trial 45 finished with value: 0.76 and parameters: {'n_estimators': 300, 'max_depth': 14, 'min_samples_split': 22, 'bootstrap': False, 'n_jobs': -1}. Best is trial 14 with value: 0.78.\u001b[0m\n",
      "\u001b[32m[I 2023-10-05 20:01:37,742]\u001b[0m Trial 46 finished with value: 0.8 and parameters: {'n_estimators': 142, 'max_depth': 14, 'min_samples_split': 20, 'bootstrap': False, 'n_jobs': -1}. Best is trial 46 with value: 0.8.\u001b[0m\n",
      "\u001b[32m[I 2023-10-05 20:01:38,213]\u001b[0m Trial 47 finished with value: 0.78 and parameters: {'n_estimators': 177, 'max_depth': 13, 'min_samples_split': 24, 'bootstrap': False, 'n_jobs': -1}. Best is trial 46 with value: 0.8.\u001b[0m\n",
      "\u001b[32m[I 2023-10-05 20:01:38,638]\u001b[0m Trial 48 finished with value: 0.78 and parameters: {'n_estimators': 155, 'max_depth': 11, 'min_samples_split': 24, 'bootstrap': False, 'n_jobs': -1}. Best is trial 46 with value: 0.8.\u001b[0m\n",
      "\u001b[32m[I 2023-10-05 20:01:39,009]\u001b[0m Trial 49 finished with value: 0.77 and parameters: {'n_estimators': 141, 'max_depth': 11, 'min_samples_split': 32, 'bootstrap': False, 'n_jobs': -1}. Best is trial 46 with value: 0.8.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 142, 'max_depth': 14, 'min_samples_split': 20, 'bootstrap': False, 'n_jobs': -1}\n",
      "Fold 1 Accuracy: 0.77\n",
      "Fold 1 F_score: 0.769792813532179\n",
      "Fold 2 Accuracy: 0.86\n",
      "Fold 2 F_score: 0.8599439775910364\n",
      "Fold 3 Accuracy: 0.81\n",
      "Fold 3 F_score: 0.8095238095238095\n",
      "Fold 4 Accuracy: 0.88\n",
      "Fold 4 F_score: 0.879951980792317\n",
      "Fold 5 Accuracy: 0.78\n",
      "Fold 5 F_score: 0.7785829307568438\n",
      "Average Accuracy across all folds: 0.8200\n",
      "Average Fscore across all folds: 0.8087\n"
     ]
    }
   ],
   "source": [
    "# Setting up the stratified k-fold cross-validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "accuracies = []  # List to store accuracy of each fold\n",
    "f1_scores = []\n",
    "fold_num = 0\n",
    "num_trial = 50\n",
    "\n",
    "# 5-fold Stratified Cross Validation loop\n",
    "for train_index, test_index in skf.split(X_indices, y_labels):\n",
    "    fold_num += 1\n",
    "\n",
    "    # Splitting the dataset for this fold\n",
    "    X_train, X_test = [X_indices[i] for i in train_index], [X_indices[i] for i in test_index]\n",
    "    y_train_labels, y_test_labels = [y_labels[i] for i in train_index], [\n",
    "        y_labels[i] for i in test_index\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    # optimize params for single fold\n",
    "    if fold_num == 1:  \n",
    "\n",
    "\n",
    "        def objective(trial):\n",
    "            params = {\n",
    "            'n_estimators' : trial.suggest_int('n_estimators', 100, 1000),\n",
    "            'max_depth' : trial.suggest_int('max_depth', 3, 15),\n",
    "            # 'max_features' : trial.suggest_categorical('max_features', ['auto', 'sqrt']), \n",
    "            'min_samples_split' : trial.suggest_int('min_samples_split', 5, 32),\n",
    "            'bootstrap' : trial.suggest_categorical('bootstrap', [True, False]),\n",
    "            'n_jobs' : trial.suggest_categorical('n_jobs', [-1]) #fixed. use all cpus\n",
    "            }\n",
    "\n",
    "            clf = RandomForestClassifier(**params)\n",
    "            clf.fit(X_train, y_train_labels)\n",
    "\n",
    "            # Making predictions on the test set\n",
    "            y_pred = clf.predict(X_test)\n",
    "\n",
    "            # Calculating and reporting the accuracy\n",
    "            accuracy = accuracy_score(y_test_labels, y_pred)\n",
    "            return accuracy\n",
    "\n",
    "\n",
    "        # optimize study\n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=num_trial) \n",
    "        print(study.best_params)\n",
    "                        \n",
    "    # Model training\n",
    "    clf = RandomForestClassifier(**study.best_params)  # change classifier here\n",
    "    clf.fit(X_train, y_train_labels)\n",
    "    \n",
    "    # clf = xgb.XGBClassifier()\n",
    "    # clf.fit(X_train, le.transform(y_train_labels))\n",
    "\n",
    "    # Making predictions on the test set\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Calculating and reporting the accuracy\n",
    "    accuracy = accuracy_score(y_test_labels, y_pred)\n",
    "    accuracies.append(accuracy)  # Storing the accuracy\n",
    "    \n",
    "    # Calculating and reporting the fscore\n",
    "    f_score = f1_score(y_test_labels, y_pred, average='weighted')\n",
    "    f_scores.append(f_score)  # Storing the accuracy\n",
    "    print(f\"Fold {fold_num} Accuracy: {accuracy}\")\n",
    "    print(f\"Fold {fold_num} F_score: {f_score}\")\n",
    "\n",
    "# Reporting the final results\n",
    "avg_accuracy = np.mean(accuracies)\n",
    "avg_fscore = np.mean(f_scores)\n",
    "print(f\"Average Accuracy across all folds: {avg_accuracy:.4f}\")\n",
    "print(f\"Average Fscore across all folds: {avg_fscore:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9da8ac55-e809-4c5f-970e-d2a1a6509be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Accuracy: 0.78\n",
      "Fold 1 F_score: 0.7799119647859143\n",
      "Fold 2 Accuracy: 0.87\n",
      "Fold 2 F_score: 0.8698828946051447\n",
      "Fold 3 Accuracy: 0.82\n",
      "Fold 3 F_score: 0.8193496587715776\n",
      "Fold 4 Accuracy: 0.89\n",
      "Fold 4 F_score: 0.88998899889989\n",
      "Fold 5 Accuracy: 0.79\n",
      "Fold 5 F_score: 0.7882851093860268\n",
      "Average Accuracy across all folds: 0.8300\n",
      "Average Fscore across all folds: 0.8295\n"
     ]
    }
   ],
   "source": [
    "import catboost as ctb\n",
    "\n",
    "ctb_clf = ctb.CatBoostClassifier(iterations=1700)\n",
    "\n",
    "# Setting up the stratified k-fold cross-validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "accuracies = []  # List to store accuracy of each fold\n",
    "f_scores = []\n",
    "fold_num = 0\n",
    "num_trial = 50\n",
    "\n",
    "# 5-fold Stratified Cross Validation loop\n",
    "for train_index, test_index in skf.split(X_indices, y_labels):\n",
    "    fold_num += 1\n",
    "\n",
    "    # Splitting the dataset for this fold\n",
    "    X_train, X_test = [X_indices[i] for i in train_index], [X_indices[i] for i in test_index]\n",
    "    y_train_labels, y_test_labels = [y_labels[i] for i in train_index], [\n",
    "        y_labels[i] for i in test_index\n",
    "    ]\n",
    "    \n",
    "\n",
    "    clf = ctb.CatBoostClassifier(iterations=2000)\n",
    "    clf.fit(X_train, y_train_labels, verbose=False)\n",
    "\n",
    "    # Making predictions on the test set\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Calculating and reporting the accuracy\n",
    "    accuracy = accuracy_score(y_test_labels, y_pred)\n",
    "    accuracies.append(accuracy)  # Storing the accuracy\n",
    "    \n",
    "    # Calculating and reporting the fscore\n",
    "    f_score = f1_score(y_test_labels, y_pred, average='weighted')\n",
    "    f_scores.append(f_score)  # Storing the accuracy\n",
    "    print(f\"Fold {fold_num} Accuracy: {accuracy}\")\n",
    "    print(f\"Fold {fold_num} F_score: {f_score}\")\n",
    "\n",
    "# Reporting the final results\n",
    "avg_accuracy = np.mean(accuracies)\n",
    "avg_fscore = np.mean(f_scores)\n",
    "print(f\"Average Accuracy across all folds: {avg_accuracy:.4f}\")\n",
    "print(f\"Average Fscore across all folds: {avg_fscore:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
